{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to deploy a BQML prediction endpoint in Kubeflow (KF Serving)\n",
    "\n",
    "This is based on:\n",
    "* https://medium.com/google-cloud/using-bigquery-and-bigquery-ml-from-kubeflow-pipelines-991a2fa4bea8\n",
    "    * To see how to run BQ from KFP\n",
    "* https://towardsdatascience.com/how-to-do-online-prediction-with-bigquery-ml-db2248c0ae5\n",
    "    * To see how to extract model weights and parametes to run the inference\n",
    "* https://medium.com/@spryd/getting-started-with-bigquery-machine-learning-bqml-564264af0adc\n",
    "    * Model idea\n",
    "\n",
    "**New stuff:**\n",
    "* Component to return a pandas df based on a BQ query - train model in BQ from KFP and export model HPs to files\n",
    "* Wrapped the online prediction code from Lak in a container by launching kfserving.KFServer\n",
    "* Deploy an online KFServing using a custom model Spec\n",
    "* We get a nice model endpoint with a lot of serving features such canary rollouts, autoscaling ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user kfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.components as comp\n",
    "import kfp.dsl as dsl\n",
    "from typing import NamedTuple\n",
    "import json\n",
    "import os\n",
    "from kfp.components import InputPath, OutputPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is for an KFP deployed on GKE, adapt your enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID='' \n",
    "KFPHOST=''\n",
    "CLIENT_ID = ''\n",
    "OTHER_CLIENT_ID = ''\n",
    "OTHER_CLIENT_SECRET = ''\n",
    "NAMESPACE = 'kubeflow-velascoluis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset velascoluis-test:mlpatterns\r\n",
      "\r\n",
      "   Last modified                              ACLs                             Labels  \r\n",
      " ----------------- ---------------------------------------------------------- -------- \r\n",
      "  21 Apr 06:55:06   Owners:                                                            \r\n",
      "                      kf10rc4-user@velascoluis-test.iam.gserviceaccount.com,           \r\n",
      "                      projectOwners                                                    \r\n",
      "                    Writers:                                                           \r\n",
      "                      projectWriters                                                   \r\n",
      "                    Readers:                                                           \r\n",
      "                      projectReaders                                                   \r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!bq show mlpatterns || bq mk mlpatterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inference code is located in an idependent container running the following code:\n",
    "```\n",
    "file:model.py\n",
    "import kfserving\n",
    "from typing import List, Dict\n",
    "import pandas as pd\n",
    "class KFServingBQPredict(kfserving.KFModel):\n",
    "    def __init__(self, name: str):\n",
    "        super().__init__(name)\n",
    "        self.name = name\n",
    "        self.ready = False\n",
    "    def predict(self, request: Dict) -> Dict:\n",
    "        values = request[\"instances\"][0]\n",
    "        inputs = pd.DataFrame(values).T\n",
    "        inputs.columns = [\"pageviews\",\"timeOnSite\",\"isNewVisit\",\"isMobile\",\"isDesktop\",\"isPaidTraffic\"]\n",
    "        numeric_weights = pd.read_csv(\"numeric.csv\").drop(['Unnamed: 0'], axis=1)\n",
    "        scaling_df = pd.read_csv(\"scaling.csv\").drop(['Unnamed: 0'], axis=1)\n",
    "        categorical_weights = pd.read_csv(\"categorical.csv\").drop(['Unnamed: 0'], axis=1)\n",
    "        pred = 0\n",
    "        for column_name in numeric_weights['input'].unique():\n",
    "            print(column_name)\n",
    "            wt = numeric_weights[numeric_weights['input'] == column_name]['input_weight'].values[0]\n",
    "            if column_name != '__INTERCEPT__':\n",
    "                print(\"in loop\")\n",
    "                meanv = scaling_df[scaling_df['input'] == column_name]['mean'].values[0]\n",
    "                stddev = scaling_df[scaling_df['input'] == column_name]['stddev'].values[0]\n",
    "                scaled_value = (inputs[column_name] - meanv) / stddev\n",
    "            else:\n",
    "                scaled_value = 1.0\n",
    "        contrib = wt * scaled_value\n",
    "        pred = pred + contrib\n",
    "        # categorical inputs\n",
    "        for column_name in categorical_weights['input'].unique():\n",
    "            category_weights = categorical_weights[categorical_weights['input'] == column_name]\n",
    "            wt = \\\n",
    "            category_weights[category_weights['category_name'] == inputs[column_name]]['category_weight'].values[0]\n",
    "            pred = pred + wt\n",
    "        return {\"predictions\": pred}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = KFServingBQPredict(\"kfserving-custom-model\")\n",
    "    kfserving.KFServer(workers=1).start([model])\n",
    "```\n",
    "\n",
    "Once we have the code we build a container with the following spec:\n",
    "\n",
    "```\n",
    "FROM python:3.7-slim\n",
    "ENV APP_HOME /app\n",
    "WORKDIR $APP_HOME\n",
    "COPY requirements.txt ./\n",
    "RUN pip install --no-cache-dir -r ./requirements.txt\n",
    "COPY src/*   ./\n",
    "CMD [\"python\", \"model.py\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bigquery_ddl(project_id: str, query_string: str, location: str) -> NamedTuple(\n",
    "    'DDLOutput', [('created_table', str), ('query', str)]):\n",
    "    \"\"\"\n",
    "    Runs BigQuery query and returns a table/model name\n",
    "    \"\"\"\n",
    "    print(query_string)\n",
    "        \n",
    "    from google.cloud import bigquery\n",
    "    from google.api_core.future import polling\n",
    "    from google.cloud import bigquery\n",
    "    from google.cloud.bigquery import retry as bq_retry\n",
    "    \n",
    "    bqclient = bigquery.Client(project=project_id, location=location)\n",
    "    job = bqclient.query(query_string, retry=bq_retry.DEFAULT_RETRY)\n",
    "    job._retry = polling.DEFAULT_RETRY\n",
    "    \n",
    "    while job.running():\n",
    "        from time import sleep\n",
    "        sleep(0.1)\n",
    "        print('Running ...')\n",
    "        \n",
    "    tblname = job.ddl_target_table\n",
    "    print('tblname:{}'.format(tblname))\n",
    "    tblname = '{}.{}'.format(tblname.dataset_id, tblname.table_id)\n",
    "    print('{} created in {}'.format(tblname, job.ended - job.started))\n",
    "    \n",
    "    from collections import namedtuple\n",
    "    result_tuple = namedtuple('DDLOutput', ['created_table', 'query'])\n",
    "    return result_tuple(tblname, query_string)\n",
    "\n",
    "\n",
    "def run_bigquery_sql_pandas(project_id: str, query_string: str, location: str, df_output_path: OutputPath(str)):\n",
    "    \"\"\"\n",
    "    Runs BigQuery query and returns a pandas dataframe\n",
    "    \"\"\"\n",
    "    print(query_string)\n",
    "        \n",
    "    from google.cloud import bigquery\n",
    "   \n",
    "    bqclient = bigquery.Client(project=project_id, location=location)\n",
    "    df = bqclient.query(query_string).to_dataframe()\n",
    "    df.to_csv (df_output_path)\n",
    "    \n",
    "\n",
    "\n",
    "def train_regression_model(ddlop, project_id):\n",
    "    query = \"\"\"CREATE OR REPLACE MODEL mlpatterns.buyer_predictor\n",
    "            OPTIONS(model_type='logistic_reg',\n",
    "            input_label_cols=['isBuyer'])\n",
    "            AS\n",
    "            SELECT\n",
    "             IF(totals.transactions IS NULL, 0, 1) AS isBuyer,\n",
    "             IFNULL(totals.pageviews, 0) AS pageviews,\n",
    "             IFNULL(totals.timeOnSite, 0) AS timeOnSite,\n",
    "             IFNULL(totals.newVisits, 0) AS isNewVisit,\n",
    "             IF(device.deviceCategory = 'mobile', 1, 0) AS isMobile,\n",
    "             IF(device.deviceCategory = 'desktop', 1, 0) AS isDesktop,\n",
    "             IF(trafficSource.medium in ('affiliate', 'cpc', 'cpm'), 1, 0) AS isPaidTraffic\n",
    "            FROM\n",
    "             `bigquery-public-data.google_analytics_sample.ga_sessions_*`\n",
    "            WHERE\n",
    "             _TABLE_SUFFIX BETWEEN '20160801' AND '20170630'\n",
    " \"\"\"    \n",
    "    print(query)\n",
    "    return ddlop(project_id, query, 'US')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def export_model_weights_numeric(sqlpandasop, project_id,model):\n",
    "    query = \"\"\"\n",
    "        SELECT\n",
    "          processed_input AS input,\n",
    "          model.weight AS input_weight\n",
    "        FROM\n",
    "          ml.WEIGHTS(MODEL {0}) AS model\n",
    "    \"\"\".format(model)\n",
    "    print(query)\n",
    "    return sqlpandasop(project_id, query, 'US')\n",
    "\n",
    "def export_model_weights_scaling(sqlpandasop, project_id,model):\n",
    "    query = \"\"\"\n",
    "        SELECT\n",
    "          input, min, max, mean, stddev\n",
    "        FROM\n",
    "          ml.FEATURE_INFO(MODEL {0}) AS model\n",
    "    \"\"\".format(model)\n",
    "    print(query)\n",
    "    return sqlpandasop(project_id, query, 'US')\n",
    "\n",
    "\n",
    "\n",
    "def export_model_weights_categorical(sqlpandasop, project_id,model):\n",
    "    query = \"\"\"\n",
    "    SELECT\n",
    "      processed_input AS input,\n",
    "      model.weight AS input_weight,\n",
    "      category.category AS category_name,\n",
    "      category.weight AS category_weight\n",
    "    FROM\n",
    "      ml.WEIGHTS(MODEL {0}) AS model,\n",
    "  UNNEST(category_weights) AS category\n",
    "    \"\"\".format(model)\n",
    "    print(query)\n",
    "    return sqlpandasop(project_id, query, 'US')\n",
    "\n",
    "\n",
    "\n",
    "def deploy_model_kfserving():\n",
    "    \n",
    "    from kubernetes import client\n",
    "    from kubernetes.client import V1Container\n",
    "    from kfserving import KFServingClient\n",
    "    from kfserving import constants\n",
    "    from kfserving import utils\n",
    "    from kfserving import V1alpha2EndpointSpec\n",
    "    from kfserving import V1alpha2PredictorSpec\n",
    "    from kfserving import V1alpha2InferenceServiceSpec\n",
    "    from kfserving import V1alpha2InferenceService\n",
    "    from kfserving import V1alpha2CustomSpec\n",
    "\n",
    "    GCR_NAME=\"velascoluis-test\"    \n",
    "    api_version = constants.KFSERVING_GROUP + '/' + constants.KFSERVING_VERSION\n",
    "    inference_service_name = \"kfserving-custom-model\"\n",
    "    namespace = utils.get_default_target_namespace()\n",
    "     \n",
    "    api_version = constants.KFSERVING_GROUP + '/' + constants.KFSERVING_VERSION\n",
    "\n",
    "    default_endpoint_spec = V1alpha2EndpointSpec(\n",
    "                          predictor=V1alpha2PredictorSpec(\n",
    "                              custom=V1alpha2CustomSpec(\n",
    "                                  #This is the custom model a v1 k8s Container\n",
    "                                  container=V1Container(\n",
    "                                      name=\"kfserving-custom-model\",\n",
    "                                      image=\"gcr.io/velascoluis-test/kfserving-custom-model:latest\"))))\n",
    "\n",
    "    isvc = V1alpha2InferenceService(api_version=api_version,\n",
    "                          kind=constants.KFSERVING_KIND,\n",
    "                          metadata=client.V1ObjectMeta(\n",
    "                              name=inference_service_name,\n",
    "                              annotations=\n",
    "                                            {\n",
    "                                                'sidecar.istio.io/inject': 'false',\n",
    "                                                'autoscaling.knative.dev/target': '1'\n",
    "                                            },\n",
    "                              namespace=namespace),\n",
    "                          spec=V1alpha2InferenceServiceSpec(default=default_endpoint_spec))\n",
    "    KFServing = KFServingClient()\n",
    "    KFServing.create(isvc)\n",
    "    \n",
    "    \n",
    "\n",
    "@dsl.pipeline(\n",
    "    name='Cascade pipeline',\n",
    "    description='Cascade pipeline'\n",
    ")\n",
    "def cascade_pipeline(\n",
    "    project_id = PROJECT_ID\n",
    "):\n",
    "    #operations\n",
    "    ddlop = comp.func_to_container_op(run_bigquery_ddl, packages_to_install=['google-cloud-bigquery'])\n",
    "    sqlpandasop =   comp.func_to_container_op(run_bigquery_sql_pandas, packages_to_install=['google-cloud-bigquery', 'pandas']) \n",
    "    deployop = comp.func_to_container_op(deploy_model_kfserving, packages_to_install=['kfserving', 'kubernetes']) \n",
    "    \n",
    "    #pipeline\n",
    "    c1 = train_regression_model(ddlop, PROJECT_ID)\n",
    "    c1_model_name = c1.outputs['created_table']\n",
    "    export_wn_op = export_model_weights_numeric(sqlpandasop, PROJECT_ID, c1_model_name)\n",
    "    export_ws_op = export_model_weights_scaling(sqlpandasop, PROJECT_ID, c1_model_name)\n",
    "    export_wc_op = export_model_weights_categorical(sqlpandasop, PROJECT_ID, c1_model_name)\n",
    "    deployer_kfserving_op = deployop().after(export_wc_op)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then this pipelimne, build the model, export the metadata, then it deploys the pre-built image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE OR REPLACE MODEL mlpatterns.buyer_predictor\n",
      "            OPTIONS(model_type='logistic_reg',\n",
      "            input_label_cols=['isBuyer'])\n",
      "            AS\n",
      "            SELECT\n",
      "             IF(totals.transactions IS NULL, 0, 1) AS isBuyer,\n",
      "             IFNULL(totals.pageviews, 0) AS pageviews,\n",
      "             IFNULL(totals.timeOnSite, 0) AS timeOnSite,\n",
      "             IFNULL(totals.newVisits, 0) AS isNewVisit,\n",
      "             IF(device.deviceCategory = 'mobile', 1, 0) AS isMobile,\n",
      "             IF(device.deviceCategory = 'desktop', 1, 0) AS isDesktop,\n",
      "             IF(trafficSource.medium in ('affiliate', 'cpc', 'cpm'), 1, 0) AS isPaidTraffic\n",
      "            FROM\n",
      "             `bigquery-public-data.google_analytics_sample.ga_sessions_*`\n",
      "            WHERE\n",
      "             _TABLE_SUFFIX BETWEEN '20160801' AND '20170630'\n",
      " \n",
      "\n",
      "        SELECT\n",
      "          processed_input AS input,\n",
      "          model.weight AS input_weight\n",
      "        FROM\n",
      "          ml.WEIGHTS(MODEL {{pipelineparam:op=Run bigquery ddl;name=created_table}}) AS model\n",
      "    \n",
      "\n",
      "        SELECT\n",
      "          input, min, max, mean, stddev\n",
      "        FROM\n",
      "          ml.FEATURE_INFO(MODEL {{pipelineparam:op=Run bigquery ddl;name=created_table}}) AS model\n",
      "    \n",
      "\n",
      "    SELECT\n",
      "      processed_input AS input,\n",
      "      model.weight AS input_weight,\n",
      "      category.category AS category_name,\n",
      "      category.weight AS category_weight\n",
      "    FROM\n",
      "      ml.WEIGHTS(MODEL {{pipelineparam:op=Run bigquery ddl;name=created_table}}) AS model,\n",
      "  UNNEST(category_weights) AS category\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"https://kf10rc4.endpoints.velascoluis-test.cloud.goog/pipeline/#/experiments/details/514cba53-3eb0-4e46-8849-bed073e7a56e\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"https://kf10rc4.endpoints.velascoluis-test.cloud.goog/pipeline/#/runs/details/bbafa1bf-828d-471e-aae1-1e96bd9d08fc\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_func = cascade_pipeline\n",
    "pipeline_filename = pipeline_func.__name__ + '.zip'\n",
    "import kfp.compiler as compiler\n",
    "compiler.Compiler().compile(pipeline_func, pipeline_filename)\n",
    "\n",
    "#Specify pipeline argument values\n",
    "arguments = {}\n",
    "\n",
    "#Get or create an experiment and submit a pipeline run\n",
    "client = kfp.Client(host=KFPHOST, client_id=CLIENT_ID, namespace=NAMESPACE, other_client_id=OTHER_CLIENT_ID,\n",
    "                        other_client_secret=OTHER_CLIENT_SECRET)\n",
    "experiment = client.create_experiment('cascade_experiment')\n",
    "\n",
    "#Submit a pipeline run\n",
    "run_name = pipeline_func.__name__ + ' run'\n",
    "run_result = client.run_pipeline(experiment.id, run_name, pipeline_filename, arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets run some predictions now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                 READY      DEFAULT_TRAFFIC CANARY_TRAFFIC  URL                                               \n",
      "kfserving-custom-... False                                                                                        \n",
      "kfserving-custom-... False                                                                                        \n",
      "kfserving-custom-... True       100                             http://kfserving-custom-model.kubeflow-velascol...\n"
     ]
    }
   ],
   "source": [
    "KFServing.get(inference_service_name, namespace=namespace, watch=True, timeout_seconds=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"predictions\": -4.328171424606712}'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "CLUSTER_IP=\"34.76.151.35\"\n",
    "SERVICE_HOSTNAME=\"kfserving-custom-model.kubeflow-velascoluis.example.com\"\n",
    "data = {}\n",
    "data = \"{\\\"instances\\\":[[700, 1000,0,0,1,0]]}\"\n",
    "MODEL_NAME=\"kfserving-custom-model\"\n",
    "import requests\n",
    "url = f\"http://{CLUSTER_IP.strip()}/v1/models/{MODEL_NAME}:predict\"\n",
    "headers = {\"Host\": SERVICE_HOSTNAME.strip()}\n",
    "result = requests.post(url, data=data, headers=headers)\n",
    "print(result.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
